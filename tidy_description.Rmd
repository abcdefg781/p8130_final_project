---
title: "project"
output: 
  pdf_document:
  latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(viridis)
library(readxl)
library(faraway)
library(broom)
library(dplyr)
library(MASS)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```


```{r message = FALSE}
# tidying data and adding a column with the average salary
law_data = read_csv("./data/Lawsuit.csv") %>% 
  janitor::clean_names() %>% 
  mutate(dept = recode_factor(dept, 
                              "1" = "Biochemistry/Molecular Biology", 
                              "2" = "Physiology",
                              "3" = "Genetics", 
                              "4" = "Pediatrics", 
                              "5" = "Medicine", 
                              "6" = "Surgery"),
         gender = recode_factor(gender, 
                                "1" = "Male", 
                                "0" = "Female"),
         clin = recode_factor(clin, 
                              "1" = "Primarily clinical emphasis", 
                              "0" = "Primarily research emphasis"),
         cert = recode_factor(cert, 
                              "1" = "Board certified", 
                              "0" = "Not certified"),
         rank = recode_factor(rank, 
                              "1" = "Assistant", 
                              "2" = "Associate", 
                              "3" = "Full professor"),
         avg_salary = (sal94 + sal95) / 2)
```

```{r}
# data exploration pt. 1
my_labels  =  list(dept = "Dept, n(%)", 
                   clin = "Clin, n(%)", 
                   cert = "Clin, n(%)", 
                   prate = "Prate", 
                   exper = "Exper", 
                   rank = "Rank, n(%)", 
                   sal94 = "Sal94", 
                   sal95 = "Sal95",
                   avg_salary = "Average Salary")

my_controls = tableby.control(
               total = F,
               test = F,
               numeric.stats = c("meansd", "medianq1q3"),
               digits = 2,
               digits.pct = 2)

table1 = tableby(gender ~ dept + clin + cert + prate + exper + rank + sal94 + sal95 + avg_salary, data = law_data, control = my_controls)

summary(table1, labelTranslations = my_labels, 
        title = "Demographics and co-morbidities ", text = T) %>% 
  knitr::kable()
```

Assumptions about residuals:
1. Normally Distributed
2. They have the same variance at every predictor (Homoscedasticity)
3. They are independent of one another
```{r}
# data exploration pt. 2
# investigate the shape of the distribution for variable ‘avg_salary’ and try different transformations
law_model = lm(avg_salary ~ dept + clin + cert + prate + exper + rank + avg_salary, data = law_data)
summary(law_model)

par(mfrow = c(2, 2))
plot(law_model)
```

Based on the residual vs. fitted values plot, there is a pattern and one can't say that the points are evenly distributed along the residuals = 0 dash line. This indicates that there is going to be a transformation of
the average salary. 

The normal Q-Q plot further emphasizes this decision since a number of data points on the near the tail on the right side are not aligned with the dash line, indicating the residuals are not normal. 

The scale-location plot is used to test for homoscedasticity and since points are approximately evenly spread around the line, we can conclude that variance of residuals are approximately constant across the range of all predictor variables. 

There is presence of point close to the boundary, dashed-line of the Cook’s distance, those have to be tested as potential outliers and a decision
have to be made about their relevance to the overal population.

* Yeo-Johnson: Test to Determine the best Transformation for average salary.
```{r}
par(mfrow = c(1, 1))
hist(law_data$avg_salary,
     main = "Untransformed Response Variable",
     xlab = "Average salary")
```
Based on the graph we see an apparent right skewness. Therefore, we are not able to use BoxCox as it does not transform negative response variables. Hence we will use the yeojohnson function from the bestNormalize package to determine the power (Lamda) at which the outcome variable needs to be raised.

```{r}
install.packages("bestNormalize")
library(bestNormalize)
yeojohnson(law_data$avg_salary)
```
Therefore, I will round up the Lamda and use the Log transformation of the response variable.

```{r}
hist(log(law_data$avg_salary),
main = "Log-Transformed Response Variable",
xlab = "Log-Transformed average salary")
```
After doing log-transformation, the histogram shows normal distribution of the response variable, in this case, the log-transformed average salary.

* Building a new Multiple Regression Model
```{r}
law_log_model = lm(log(avg_salary) ~ dept + clin + cert + prate + exper + rank + avg_salary, data = law_data)

summary(law_log_model)
```





