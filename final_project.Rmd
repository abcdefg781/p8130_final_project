---
title: "P8130_final_project"
author: "Michael Yan"
date: "11/15/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(viridis)
library(dplyr)
library(bestNormalize)
library(arsenal)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```


```{r message = FALSE}
# tidying data and adding a column with the average salary
law_data = read_csv("./data/Lawsuit.csv") %>% 
  janitor::clean_names() %>% 
  mutate(dept = recode_factor(dept, 
                              "1" = "Biochemistry/Molecular Biology", 
                              "2" = "Physiology",
                              "3" = "Genetics", 
                              "4" = "Pediatrics", 
                              "5" = "Medicine", 
                              "6" = "Surgery"),
         gender = recode_factor(gender, 
                                "1" = "Male", 
                                "0" = "Female"),
         clin = recode_factor(clin, 
                              "1" = "Primarily clinical emphasis", 
                              "0" = "Primarily research emphasis"),
         cert = recode_factor(cert, 
                              "1" = "Board certified", 
                              "0" = "Not certified"),
         rank = recode_factor(rank, 
                              "1" = "Assistant", 
                              "2" = "Associate", 
                              "3" = "Full professor"),
         avg_salary = (sal94 + sal95) / 2)
```

```{r}
# data exploration pt. 1
my_labels  =  list(dept = "Dept, n(%)", 
                   clin = "Clin, n(%)", 
                   cert = "Cert, n(%)", 
                   prate = "Prate", 
                   exper = "Exper", 
                   rank = "Rank, n(%)", 
                   sal94 = "Sal94", 
                   sal95 = "Sal95",
                   avg_salary = "Average Salary")

my_controls = tableby.control(
               total = T,
               test = T,
               numeric.stats = c("meansd", "medianq1q3"),
               digits = 2,
               digits.pct = 2)

table1 = tableby(gender ~ dept + clin + cert + prate + exper + rank + sal94 + sal95 + avg_salary, data = law_data, control = my_controls)

summary(table1, labelTranslations = my_labels, 
        title = "EDA", text = T) %>% 
  knitr::kable()
```


* Yeo-Johnson: Test to Determine the best Transformation for average salary.
```{r}
# data exploration pt. 2
# investigate the shape of the distribution for variable ‘avg_salary’ and try different transformation
hist(law_data$avg_salary,
     main = "Untransformed Response Variable",
     xlab = "Average salary")
```

Based on the graph we see an apparent right skewness. Therefore, we are not able to use BoxCox as it does not transform negative response variables. Hence we will use the yeojohnson function from the bestNormalize package to determine the power (Lamda) at which the outcome variable needs to be raised.

```{r}
yeojohnson(law_data$avg_salary)
```

Therefore, we will round up the Lamda and use the Log transformation of the response variable.

```{r}
hist(log(law_data$avg_salary),
main = "Log-Transformed Response Variable",
xlab = "Log-Transformed average salary") 
```

After doing log-transformation, the histogram shows an approximate normal distribution of the response variable, in this case, the log-transformed average salary.
```{r}
law_data_1= read_csv("./data/Lawsuit.csv") %>% 
  janitor::clean_names() 

law_data_cor = law_data_1 %>% 
  mutate(log_sal = log((sal94 + sal95) / 2)) %>% 
  dplyr::select(-id,-sal94,-sal95)
  
library(corrplot)
L_data = cor(as.matrix(law_data_cor))
corrplot(L_data, method = "color",  
         type = "upper", order = "hclust", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col = "darkblue", tl.srt = 45, #Text label color and rotation
         # hide correlation coefficient on the principal diagonal
         diag = FALSE 
         )
```


* Find confounders
```{r}
# Fit the model with only one variable:gender
law_data_change = law_data %>% 
  select(gender,dept,clin,cert,exper,rank,avg_salary)

fit_sum = lm(log(avg_salary) ~ gender,data = law_data_change) %>% 
  summary() %>% 
  broom::tidy() %>% 
  mutate(model = "log(avg_salary) ~ gender")

#fit all other predicators with gender
p_value_list = vector("list",length = 5)
for (i in 2:6) {
  fitml = 
    as.formula(paste0("log(avg_salary) ~ gender +",names(law_data_change)[i],collapse = ""))
  p_value_list[[i - 1]] = summary(lm(fitml,data = law_data_change ))
}


p_value = vector("list",length = 5)
for (i in 1:5) {
  p_value[[i]] = broom::tidy(p_value_list[[i]]) %>% 
    mutate(
      model = paste0("log(avg_salary) ~ gender +",names(law_data_change)[i + 1],collapse = "")
    )
}

# make a table to show the result
p_value = bind_rows(fit_sum,p_value)
confounder = p_value %>% 
    dplyr::select(model,everything()) %>% 
    filter(term == "genderFemale") %>% 
    mutate(change_rate = round((-0.3853044 - estimate)/(-0.3853044),3)) %>% 
    dplyr::select(model,term,estimate,change_rate)

knitr::kable(confounder)
```

The criterion for finding confounders of `gender` is that after adding another variable into the existed model,the change in slope of gender is over 10%.

After running the code, we found that for variable `dept`,`clin`,``cert`,`prate` and `exper`
the change of slope is over 10%, so these five variables are all confounders.


* Find interactions
```{r}
#fit all other predicators with gender
interaction_list = vector("list",length = 5)
for (i in 2:6) {
  fitml_inter = 
    as.formula(paste0("log(avg_salary) ~ gender+dept+clin+cert+exper+rank+gender * ",names(law_data_change)[i],collapse = ""))
  interaction_list[[i - 1]] = summary(lm(fitml_inter,data = law_data_change))
}
#fit predicators with gender
interaction = vector("list",length = 5)
for (i in 2:6) {
  fitml_inter = 
    as.formula(paste0("log(avg_salary) ~ gender+dept+clin+cert+exper+rank+gender * ",names(law_data_change)[i],collapse = ""))
  interaction[[i - 1]] = summary(lm(fitml_inter,data = law_data_change))
}

interaction_p_value = vector("list",length = 5)
for (i in 1:5) {
  interaction_p_value[[i]] = broom::tidy(interaction[[i]]) %>% 
    mutate(
      model1 = paste0("log(avg_salary) ~ gender+dept+clin+cert+exper+rank+gender *",names(law_data_change)[i + 1],collapse = "")
    )
}

# make a table to show the results
interaction_p_value = bind_rows(interaction_p_value)
interaction_table = interaction_p_value %>% 
    dplyr::select(model1,everything()) %>% 
    filter(term != "(Intercept)") %>% 
    dplyr::select(model1,everything())

knitr::kable(interaction_table)
```

As we can see from the result, when we focus on p-value,the only interaction is `rank` and `exper`. The effect of gender on salary is different with respect to the rank and exper. 

```{r}
# final model
reg_n_prate = lm(log(avg_salary)~ gender * rank + gender*exper+ dept + clin + cert , data = law_data_change) 
summary(reg_n_prate)
```


```{r}
# seperate regression models for rank
rank_assi = 
  law_data_change %>% 
  filter(rank == "Assistant") 

rank_asso =
  law_data_change %>% 
  filter(rank == "Associate")

rank_prof = 
  law_data_change %>% 
  filter(rank == "Full professor")

# Rank = Assistant
fit_assi = lm(log(avg_salary)~ gender*exper+ dept + clin + cert, data = rank_assi)
summary(fit_assi)

# Rank = Associate: gender not significant
# means no discrimination between male and female in rank of associate ?
fit_asso = lm(log(avg_salary)~ gender*exper+ dept + clin + cert, data = rank_asso)
summary(fit_asso)

# Rank = Full professor: gender not significant
# means no discrimination between male and female in rank of full professor?
fit_prof =lm(log(avg_salary)~  gender*exper+ dept + clin + cert, data = rank_prof)
summary(fit_prof)
```


Assumptions about residuals:
1. Normally Distributed
2. They have the same variance at every predictor (Homoscedasticity)
3. They are independent of one another

```{r}
law_model = lm(log(avg_salary)~ gender * rank + dept + clin + cert + exper * gender, data = law_data_change)

par(mfrow = c(2, 2))
plot(law_model)
```
